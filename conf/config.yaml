defaults:
  - search_space: llama_mixed_precision
  - _self_

project_name: "EMPAS"
seed: 42

# Global Settings
model_type: "llama"
target_device: "cuda"

evaluator:
  type: "dummy"
  batch_size: 1
  seq_len: 128